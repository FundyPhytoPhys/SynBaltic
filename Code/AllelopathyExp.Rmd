---
title: "AllelopathyExp"
author:
- Sylwia Sliwinska-Wilczewska
date: "`r format(Sys.Date())`"
output:
bookdown::html_document2:
    code_folding: show
    keep_md: yes
    toc: TRUE
    toc_float: TRUE
    toc_depth: 6
    fig_caption: yes
bibliography: BalticPhotoperiod.bib
csl: plos-one.csl
editor_options: 
  markdown: 
    wrap: 72
---

# Set Chunk Options

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
knitr::opts_chunk$set(fig.path='Figs/')
```

# Introduction

AllelopathyExp.Rmd imports: 
Allelopathy_culture catalog from google sheet, Growth catalog from google sheet,
PAMAS.....

# Load libraries

```{r load libraries}
library(kableExtra)
library(tidyverse)
library(lubridate)
library(stringr)
library(broom)
library(knitr)
library(OneR)
library(zoo)
library(strucchange)
library(dplyr)
library(magrittr)
library(googledrive)
library(googlesheets4)
library(readxl)
library(ggspectra)
library(ggpubr)
library(caret)
library(gcookbook)
library(scales)
```

# Set Project Variables

```{r set project variables}
Project <- "Allelopathy"
DataOut <- file.path("..", "Data", "CleanedData", "AllelopathyExp")

PlotsPath <- file.path("..", "Output", "Plots", "AllelopathyExp")
RDSPlotPath <- file.path("..", "Output", "PlotsRDS", "AllelopathyExp")
RDSTablePath <- file.path("..", "Output", "TablesRDS", "AllelopathyExp")
```

# Import MetaDataCatalog

Load Allelopathy_MetaDataCatalog
```{r load local catalog, message = FALSE, warning = FALSE, echo=FALSE}
gs4_deauth()

# this is the URL or ID of a Sheet readable by anyone (with a link)

CultureCatalog <- read_sheet("https://docs.google.com/spreadsheets/d/14MgZTFyx0kqrhEfeA5zOZwDnQN57Q3-X9N8aHXIoBH0/edit#gid=0") %>%
  #mutate(Date = as.numeric(Date)) %>%
  mutate(Start_Date = ymd(`Start_Date`)) %>% 
  mutate(End_Date = ymd(`End_Date`)) %>% 
    mutate("PlateNo"=as.double("PlateNo")) %>% 
  mutate("WellNo"=as.double("WellNo"))
```

# Import ClarioSTAR growth catalog

Load Allelopathy_GrowthCatalog
```{r load local catalog, message = FALSE, warning = FALSE, echo=FALSE}
gs4_deauth()

# this is the URL or ID of a Sheet readable by anyone (with a link)

GrowthData <- read_sheet("https://docs.google.com/spreadsheets/d/1yd5_J9QhT7Dy0sn1gvYBy9jM_zFGdJuIEhXWINbNmTw/edit#gid=0") %>%
  #mutate(Date = as.numeric(Date)) %>%
  mutate(ObsDate = ymd(`ObsDate`)) %>% 
  drop_na(OD680) %>% 
  select(-c("6well_Plate")) %>% 
  mutate("6well_PlateNo"=as.double("6well_PlateNo")) %>% 
  mutate("6well_WellNo"=as.double("6well_WellNo"))
```

# Merge data

```{r}

GrowthMeta <- CultureCatalog %>%
  full_join(., GrowthData, by = c("Sample_ID"="Sample_ID")) %>% 
  drop_na(OD680_blank) %>%
  drop_na(PAR)

```

```{r}
GrowthMeta <- GrowthMeta %>%
group_by(Sample_ID) %>%
  arrange(ObsDate) %>%
  mutate(E_days = as.numeric((ObsDate - Start_Date[1]))) %>%
ungroup() 
```



# Calculate the mean

```{r}
# GrowthMetamean<-GrowthMeta %>% 
#   group_by(Sample_ID, Donor_GrowthPhase, Content, Treatment, Donor_Strain) %>%
#   mutate(meanOD680_blank = mean(OD680_blank)) %>% 
#   mutate(sdOD680_blank = sd(OD680_blank)) %>% 
#   ungroup() 
```


# Create preliminary plot

```{r preliminary plot}
GrowthMeta %>%
  #filter(Target_Species == "Cyanobium") %>% 
  #filter(Treatment == "Stationary") %>% 
  ggplot() +
  geom_point(aes(x = E_days, y =OD680_blank, colour=as.factor(Donor_Strain)), show.legend = T) +
  geom_smooth(aes(x = E_days, y =OD680_blank, colour=as.factor(Donor_Strain)), method = lm, show.legend = F, alpha = 0.1) +
  # geom_errorbar(aes(x = Dilution, ymin = meanCount104-sdCount104, ymax = meanCount104+sdCount104)) +
  # labs(y = "Number of cells (N" ~10^4 ~mL^-1~")", x = "Culture concentration (mL)") +
  #scale_x_continuous(breaks=seq(0, 7, by = 1)) +
  # coord_cartesian(ylim = c (0, 12)) +
  ggh4x::facet_nested(cols = vars(Target_Species), rows = vars(Donor_GrowthPhase), labeller = labeller(Ex_WL = label_both, strain = label_value, WL = label_both, Photoperiod = label_both, Par_ue = label_both)) +
  theme_bw()
```

---------------------------------------------- PAMAS -------------------------------------------------------

# IMPORT PAMAS DATA

# Set project variables and list files in the extracted folder

```{r set project variables, warning = FALSE, echo = FALSE}
Project <- "BalticPhotoperiod"
zip_file <- file.path("..", "Data", "RawData", "PamasData.zip")

# List files in the extracted folder with a ".txt" extension
CountFiles <- unzip(zip_file, list = TRUE)
CountFiles <- CountFiles[grepl(".txt$", CountFiles$Name), "Name"]
print(CountFiles)

FileID <- "PAMAS"
FileEncode <- "UTF-8" 
HeaderRows <- 9
DelimCS <- "\t"
```

# Read fread_plus function

```{r data read adds filename and cdate, warning=FALSE, message=FALSE, echo=FALSE}
# Define function to read and process each file
fread_plus <- function(Flnm, FileEncode, Delim) {
  con <- unz(zip_file, Flnm)
  
  # Read the file using read.table
  data <- read.table(con, skip = HeaderRows, encoding = FileEncode, sep = Delim, header = TRUE)
  
  # Use tryCatch to handle errors during the closing of the connection
  tryCatch(
    close(con),
    error = function(e) {
      warning("Error closing connection: ", e$message)
    })
  
  data <- data %>%
    mutate(Filename = Flnm, CDateTime = ymd_hms(file.info(zip_file)$ctime)) 
  return(data)
}

# Use map_df to read and process all files in CountFiles
CountTidy <- CountFiles %>%
  map_df(~fread_plus(Flnm = ., FileEncode = FileEncode, Delim = DelimCS))
```

# Clean up the filename column

```{r clean up df, warning = FALSE, echo = FALSE}
CountTidy <- CountTidy %>% 
  mutate(Filename = str_remove(string = Filename, pattern = ".txt")) %>%
  mutate(Filename = str_remove(string = Filename, pattern = "../PamasData/")) %>%
  separate(Filename, into = c("Date", "Strain", "Dilution", "Device"), sep = "([\\/\\/\\_\\_\\_\\_])", remove = FALSE) %>% 
  mutate(Date = as.double(`Date`)) %>%
  mutate(Date = ymd_hm(`Date`))
```

# Tidy PAMAS df

```{r tidy TargetPamasData, warning = FALSE, echo = FALSE}
# figure out how to read and rename these columns from the file rather than manually
NewNames <- c("PAMASDate", "Time", ">0.70",">0.80", ">0.90", ">1.00", ">1.20", ">1.50", ">2.00",">3.00", ">4.00", ">5.00", ">6.00", ">7.00", ">10.00", ">12.00",
">15.00",">20.00", "Filename", "Date","Strain", "Dilution", "Device", "cdatetime")

OldNames <- colnames(CountTidy)

PamasTidy <- CountTidy %>%
rename_with(~NewNames[which(OldNames == .x)], .cols = OldNames) %>%
  mutate(datetime = paste(PAMASDate, Time),
         datetime = mdy_hms(datetime))
```

# Tidy PAMAS df

```{r}
PamasTidy <- PamasTidy %>%
mutate(`S0.7` = as.numeric(`>0.70`) - as.numeric(`>0.80`),
       `S0.8` = as.numeric(`>0.80`) - as.numeric(`>0.90`),
       `S0.9` = as.numeric(`>0.90`) - as.numeric(`>1.00`),
       `S1.0` = as.numeric(`>1.00`) - as.numeric(`>1.20`),
       `S1.2` = as.numeric(`>1.20`) - as.numeric(`>1.50`),
       `S1.5` = as.numeric(`>1.50`) - as.numeric(`>2.00`),
       `S2.0` = as.numeric(`>2.00`) - as.numeric(`>3.00`),
       `S3.0` = as.numeric(`>3.00`) - as.numeric(`>4.00`),
       `S4.0` = as.numeric(`>4.00`) - as.numeric(`>5.00`),
       `S5.0` = as.numeric(`>5.00`) - as.numeric(`>6.00`),
       `S6.0` = as.numeric(`>6.00`) - as.numeric(`>7.00`),
       `S7.0` = as.numeric(`>7.00`) - as.numeric(`>10.00`),
       `S10.0` = as.numeric(`>10.00`) - as.numeric(`>12.00`),
       `S12.0` = as.numeric(`>12.00`) - as.numeric(`>15.00`),
       `S15.0` = as.numeric(`>15.00`) - as.numeric(`>20.00`),
       `S20.0` = as.numeric(`>20.00`))

PamasTidy <- PamasTidy %>%
  pivot_longer(., cols = c("S0.7", "S0.8", "S0.9", "S1.0", "S1.2", "S1.5", "S2.0", "S3.0", "S4.0", "S5.0", "S6.0", "S7.0", "S10.0", "S12.0", "S15.0", "S20.0"), names_to = "CellSize_um", values_to = "Count") %>%
  mutate_at("CellSize_um", str_replace, "S", "") %>%
  mutate(CellSize_um = as.numeric(CellSize_um)) %>%
  group_by(CellSize_um, Strain, Dilution) %>%
  mutate(meanCount = mean(Count), 
         sdCount = sd(Count)) %>%
  ungroup() %>%
  select(c(PAMASDate, Filename, Date, Strain, Dilution, cdatetime, CellSize_um, Count, meanCount, sdCount))
```

# Rename variables for consistency

```{r}
PamasTidy<-PamasTidy %>% 
  rename(ObsDate=Date) %>%
  rename(FilenamePAMAS=Filename) %>% 
  select(-c(cdatetime, PAMASDate))
```

# Create preliminary plot

```{r preliminary plot}
PamasTidy %>%
  mutate(meanCount104 = meanCount/10000) %>%
  mutate(sdCount104 = sdCount/10000) %>%
  filter(CellSize_um < 4) %>% 
  ggplot() +
  geom_point(aes(x = Dilution, y =meanCount104, label = Strain)) +
  geom_errorbar(aes(x = Dilution, ymin = meanCount104-sdCount104, ymax = meanCount104+sdCount104)) +
  labs(y = "Number of cells (N" ~10^4 ~mL^-1~")", x = "Culture concentration (mL)") +
  scale_y_continuous(breaks=seq(0, 12, by = 4)) +
  coord_cartesian(ylim = c (0, 12)) +
  ggh4x::facet_nested(rows = vars(CellSize_um), cols = vars(Strain), labeller = labeller(Ex_WL = label_both, strain = label_value, WL = label_both, Photoperiod = label_both, Par_ue = label_both)) +
  theme_bw()
```
# Removed unnecessary files from the environment

```{r removed unnecessary files from the environment}
rm(CountTidy)
```

# Save rds for further analysis if needed

```{r save rds}
# saveRDS(PamasTidy, file.path(DataOut, paste(Project, "Imported_PamasData.Rds", sep = "_"), fsep = .Platform$file.sep), ascii = FALSE, version = NULL, compress = "xz", refhook = NULL)
```










--------------------------------------------------- MD Pico --------------------------------------

# IMPORT MD PICO CORRELATION DATA

```{r set project variables, warning = FALSE, echo = FALSE}
Project <- "BalticPhotoperiod"
zip_file <- file.path("..", "Data", "RawData", "MDPico.zip")

# List files in the extracted folder with a ".txt" extension
CountFiles <- unzip(zip_file, list = TRUE)
CountFiles <- CountFiles[grepl(".csv$", CountFiles$Name), "Name"]
print(CountFiles)

FileID <- "ExperimentSummaryData"
FileEncode <- "UTF-8" 
HeaderRows <- 0
DelimCS <- ","
```

# Read fread_plus function

```{r data read adds filename and cdate, warning=FALSE, message=FALSE, echo=FALSE}
# Define function to read and process each file
fread_plus <- function(Flnm, FileEncode, Delim) {
  con <- unz(zip_file, Flnm)
  
  # Read the file using read.table
  data <- read.table(con, skip = HeaderRows, encoding = FileEncode, sep = Delim, header = TRUE)
  
  # Use tryCatch to handle errors during the closing of the connection
  tryCatch(
    close(con),
    error = function(e) {
      warning("Error closing connection: ", e$message)
    })
  
  data <- data %>%
    mutate(Filename = Flnm, CDateTime = ymd_hms(file.info(zip_file)$ctime)) 
  return(data)
}

# Use map_df to read and process all files in CountFiles
MDPicoTidy <- CountFiles %>%
  map_df(~fread_plus(Flnm = ., FileEncode = FileEncode, Delim = DelimCS))
```

```{r tidy CountTidy}

MDPicoTidy <- MDPicoTidy %>% 
  select(-c("Concentration", "Group", "Compound", "CDateTime")) %>% # remove superfluous columns
  mutate(Filename = str_remove(string = Filename, pattern = ".csv")) %>%
  mutate(Filename = str_remove(string = Filename, pattern = "../MDPico/")) %>%
  separate(Filename, into = c("ObsDate", "Project", "Initials",  "PlateNr", "IndStud", "Organism", "Count"), sep = "([\\/\\/\\_\\_\\_\\_\\_])", remove = FALSE) %>%
  select(-c("IndStud", "Organism", "Count")) %>% 
  mutate(ObsDate = ymd_hm(ObsDate)) 

```


Load MDPicoMetaData catalog
```{r load local metadatacatalog, message = FALSE, warning = FALSE, echo=FALSE}
gs4_deauth()

# this is the URL or ID of a Sheet readable by anyone (with a link)

MDPicoMetaData <- read_sheet("https://docs.google.com/spreadsheets/d/1Lerp5u25kzBtaBbnOYElYqUP59cn68gJpxxayhnGdkw/edit#gid=0") %>%
  #mutate(Date = as.numeric(Date)) %>%
  mutate(Date = ymd_hm(`Date`)) %>%
  separate(Date, into = c("Date_count", "Time_count"), sep = " ", remove = FALSE) %>%
  mutate(Date_count = ymd(`Date_count`)) 
```

# Read MetaData Catalog

```{r read locally stored metadata from rds}
CultureCatalog <- readRDS(file = file.path("..", "Data", "ImportedData", "ImportedMetaData", "CultureCatalog.Rds"))

CultureCatalog<-CultureCatalog %>% 
  select(-c(PrimaryOperator, Temp_c, ExpCul, ExpStartTime, O2_Category, Optode, OptodeCh, OptodeMeasure))
```

# Merge Pigment and Culture catalog

```{r}
MDPicoMeta <- MDPicoMetaData %>%
  left_join(., CultureCatalog, by = c("SampleID" = "SampleID")) %>% 
  drop_na(Strain)
```

# check if I do not lost some data!

```{r}
MDPicoAll <- MDPicoTidy %>%
  mutate(PlateNr = as.double(PlateNr)) %>%
  left_join(., MDPicoMeta, by = c("Well.Name" = "WellNumber", "PlateNr" = "PlateNumber")) %>% 
  drop_na(Strain)
```

```{r, warning = FALSE}
MDPicoAll <- MDPicoAll %>%
  mutate(culture_inocul_L = as.double(culture_inocul_L)) %>%
  mutate(CapAreaPercentage = as.double(CapAreaPercentage)) %>%

  mutate(CellmL_MDPico = (`Cell.Count` * (0.001/culture_inocul_L)) /(CapAreaPercentage/100)) %>%
  # mutate(cellsml = `cellsmlwithoutpercentage`/(CapAreaPercentage/100))
group_by(Date, SampleID) %>%

summarize(Well.Name, Cell.Count, Filename, ObsDate, PlateNr, PlateID, SampleID, Date, Date_count, Time_count, media_inocul_L, culture_inocul_L, CapAreaPercentage, Run, Strain, ExpDate, Par_ue, Photoperiod, PARPhotonDose_day, Tube, O2, WL, LightShape, ExpEndDate, CellmL_MDPico, meanCellmL_MDPico = mean(CellmL_MDPico), sdCellmL_MDPico = sd(CellmL_MDPico)) %>%

ungroup() %>%
  
group_by(SampleID) %>%
  arrange(Date_count) %>%
  mutate(E_days = as.numeric((Date_count - ExpDate[1]))) %>%
ungroup() %>% 
  rename(Cell_Count=Cell.Count) %>% 
  rename(Well_Name=Well.Name) %>% 
  rename(MeasDate = ObsDate) %>% 
  rename(ObsDateTime = Date) %>% 
  rename(ObsDate_count = Date_count) %>% 
  rename(ObsTime_count = Time_count) %>% 
  rename(FilenameMDPico=Filename)  
```

# Create Preliminary plot

```{r preliminary plot}
MDPicoAll %>%
  ggplot() +
  geom_point(aes(x = E_days, y = meanCellmL_MDPico)) +
  #geom_errorbar(aes(x = E_days, ymin = meanChla_ugmL-sdChla_ugmL, ymax = meanChla_ugmL+sdChla_ugmL)) +
  #labs(y = "Chl a content (µg" ~mL^-1~")", x = "Time (d)") +
  # scale_x_continuous(breaks=seq(0, 14, by = 7)) +
  # coord_cartesian(xlim = c (-1, 15)) +
  ggh4x::facet_nested(rows = vars(Par_ue), cols = vars(Strain, Photoperiod), labeller = labeller(Ex_WL = label_both, strain = label_value, Par_ue = label_both, WL = label_both, Photoperiod = label_value)) +
  theme_bw()
```




# Cleaning the environment

```{r}
rm(lmCar, lmChla, lmPC, lmPE, my_dataAPC, my_dataCar, my_dataChla, my_dataPC, my_dataPE, Olis, OLISSpectraMeta, PigmentsClarioClean, data_textPaersonChla, data_textPaersonCar, data_textPaersonPE, data_textPaersonPC, data_textPaersonAPC, ClarioPigmentAPC, ClarioPigmentPC, ClarioPigmentPE, ClarioPigmentCar, ClarioPigmentChla)
```

# Save RDS that create stats and tables

```{r save rds}
saveRDS(PigmentsCorrelation, file.path(RDSTablePath, paste(Project, "Tab_PigmentsCorrelation.Rds", sep = "_"), fsep = .Platform$file.sep), ascii = FALSE, version = NULL, compress = "xz", refhook = NULL)
```

# Save Rds for further analysis if needed

```{r save rds}
# saveRDS(PigmentsClarioOlisCorr, file.path(DataOut, paste(Project, "Imported_PigmentsClarioOlisCorrData.Rds", sep = "_"), fsep = .Platform$file.sep), ascii = FALSE, version = NULL, compress = "xz", refhook = NULL)
```



# Correlations from Polish flowcytometer (BD Accuri) and Polish Spec if needed

```{r}
# GrowthClarioN <- GrowthClario %>%
#   mutate(OD750N = case_when(
#           Strain == 'BA77G' ~ 5766620.03*OD750+5146.44,
#          Strain == 'BA56G' ~ 815627.77*OD750-6499.89, 
#          Strain == 'BA48R' ~ 110516351.55*OD750-568505.87,
#          Strain == 'BA127R' ~ 124271003.22*OD750-1691760.02))
```


